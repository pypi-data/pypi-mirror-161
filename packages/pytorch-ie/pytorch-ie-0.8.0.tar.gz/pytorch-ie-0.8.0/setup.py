# -*- coding: utf-8 -*-
from setuptools import setup

package_dir = \
{'': 'src'}

packages = \
['pytorch_ie',
 'pytorch_ie.core',
 'pytorch_ie.data',
 'pytorch_ie.data.datamodules',
 'pytorch_ie.data.datasets',
 'pytorch_ie.data.datasets.hf_datasets',
 'pytorch_ie.models',
 'pytorch_ie.models.genre',
 'pytorch_ie.models.modules',
 'pytorch_ie.taskmodules',
 'pytorch_ie.utils']

package_data = \
{'': ['*']}

install_requires = \
['datasets>=2.3.2,<3.0.0',
 'huggingface-hub>=0.5.1,<0.6.0',
 'pytorch-lightning>=1.6.1,<2.0.0',
 'torchmetrics>=0.8.0,<0.9.0',
 'transformers>=4.18.0,<5.0.0']

setup_kwargs = {
    'name': 'pytorch-ie',
    'version': '0.8.0',
    'description': 'State-of-the-art Information Extraction in PyTorch',
    'long_description': '# PyTorch-IE: State-of-the-art Information Extraction in PyTorch\n\n[![PyPI](https://img.shields.io/pypi/v/pytorch-ie.svg)][pypi status]\n[![Status](https://img.shields.io/pypi/status/pytorch-ie.svg)][pypi status]\n[![Python Version](https://img.shields.io/pypi/pyversions/pytorch-ie)][pypi status]\n[![License](https://img.shields.io/pypi/l/pytorch-ie)][license]\n\n[![Read the documentation at https://pytorch-ie.readthedocs.io/](https://img.shields.io/readthedocs/pytorch-ie/latest.svg?label=Read%20the%20Docs)][read the docs]\n[![Tests](https://github.com/christophalt/pytorch-ie/workflows/Tests/badge.svg)][tests]\n[![Codecov](https://codecov.io/gh/christophalt/pytorch-ie/branch/main/graph/badge.svg)][codecov]\n\n[![pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white)][pre-commit]\n[![Black](https://img.shields.io/badge/code%20style-black-000000.svg)][black]\n\n[pypi status]: https://pypi.org/project/pytorch-ie/\n[read the docs]: https://pytorch-ie.readthedocs.io/\n[tests]: https://github.com/christophalt/pytorch-ie/actions?workflow=Tests\n[codecov]: https://app.codecov.io/gh/christophalt/pytorch-ie\n[pre-commit]: https://github.com/pre-commit/pre-commit\n[black]: https://github.com/psf/black\n\n## ðŸ¤¯ What\'s this about?\n\nThis is an experimental framework that aims to combine the lessons learned from five years of information extraction research.\n\n-   **Focus on the core task:** The main goal is to develop information extraction methods not dataset loading and evaluation logic. We use external well-maintained libraries for non-core functionality. PyTorch-Lightning for training and logging, Huggingface datasets for dataset reading, and Huggingface evaluate for evaluation (coming soon).\n-   **Sharing is caring:** Being able to quickly and easily share models is key to promote your work and facilitate further research. All models developed in PyTorch-IE can be easily shared via the Huggingface model hub. This further allows to quickly build demos based on Huggingface spaces, gradio or streamlit.\n-   **Unified document format:** A unified document format allows for quick experimentation on any dataset or task.\n-   **Beyond sentence level:** Most information extraction frameworks assume text inputs at a sentence granularity. We do not make any assumption on the granularity but generally aim for document-level information extraction.\n-   **Beyond unstructured text:** Unstructured text is only one possible area for information extraction. We developed the framework to also support information extraction from semi-structured text (e.g. HTML), two-dimensional text (e.g. OCR\'d images), and images.\n-   **Character-level annotation and evaluation:** Many information extraction frameworks annotate and evaluate on a token level. We believe that annotation and evaluation should be done on a character level as this also considers the suitability of the tokenizer for the task.\n-   **Make no assumptions on the structure of models:** The last years have seen many different and creative approaches to information extraction and a framework that imposes a structure on those will most certainly be to limiting. With PyTorch-iE you have full control over how a document is prepared for a model and how the model is structured. The logic is self-contained and thus can be easily shared and inspected by others. The only assumption we make is that the input is a document and the output are targets (training) or annotations (inference).\n\n## ðŸš€ï¸ Quickstart\n\n```console\n$ pip install pytorch-ie\n```\n\n## ðŸ”­ Demos\n\n| Task                                                       | Link (Huggingface Spaces)                                                   |\n| ---------------------------------------------------------- | --------------------------------------------------------------------------- |\n| Named Entity Recognition (Span-based)                      | [LINK](https://huggingface.co/spaces/pie/NER)                               |\n| Joint Named Entity Recognition and Relation Classification | [LINK](https://huggingface.co/spaces/pie/Joint-NER-and-Relation-Extraction) |\n\n## ðŸ“š Datasets\n\nWe parse all datasets into a common format that can be loaded directly from the model hub via Huggingface datasets. The documents are cached in an arrow table and serialized / deserialized on the fly. Any changes or preprocessing applied to the documents will be cached as well.\n\n```python\nimport datasets\n\ndataset = datasets.load_dataset("pie/conll2003")\n\nprint(dataset["train"][0])\n# >>> CoNLL2003Document(text=\'EU rejects German call to boycott British lamb .\', id=\'0\', metadata={})\n\ndataset["train"][0].entities\n# >>> AnnotationList([LabeledSpan(start=0, end=2, label=\'ORG\', score=1.0), LabeledSpan(start=11, end=17, label=\'MISC\', score=1.0), LabeledSpan(start=34, end=41, label=\'MISC\', score=1.0)])\n\nentity = dataset["train"][0].entities[1]\n\nprint(f"[{entity.start}, {entity.end}] {entity}")\n# >>> [11, 17] German\n```\n\n## âš¡ï¸ Example\n\n**Note:** Setting `num_workers=0` in the pipeline is only necessary when running an example in an\ninteractive python session. The reason is that multiprocessing doesn\'t play well with the interactive python\ninterpreter, see [here](https://docs.python.org/3/library/multiprocessing.html#using-a-pool-of-workers)\nfor details.\n\n### Span-classification-based Named Entity Recognition\n\n```python\nfrom dataclasses import dataclass\n\nfrom pytorch_ie.annotations import LabeledSpan\nfrom pytorch_ie.auto import AutoPipeline\nfrom pytorch_ie.core import AnnotationList, annotation_field\nfrom pytorch_ie.documents import TextDocument\n\n@dataclass\nclass ExampleDocument(TextDocument):\n    entities: AnnotationList[LabeledSpan] = annotation_field(target="text")\n\ndocument = ExampleDocument(\n    "â€œMaking a super tasty alt-chicken wing is only half of it,â€ said Po Bronson, general partner at SOSV and managing director of IndieBio."\n)\n\n# see below for the long version\nner_pipeline = AutoPipeline.from_pretrained("pie/example-ner-spanclf-conll03", device=-1, num_workers=0)\n\nner_pipeline(document, predict_field="entities")\n\nfor entity in document.entities.predictions:\n    print(f"{entity} -> {entity.label}")\n\n# Result:\n# IndieBio -> ORG\n# Po Bronson -> PER\n# SOSV -> ORG\n```\n\nTo create the same pipeline as above without `AutoPipeline`:\n\n```python\nfrom pytorch_ie.auto import AutoTaskModule, AutoModel\nfrom pytorch_ie.pipeline import Pipeline\n\nmodel_name_or_path = "pie/example-ner-spanclf-conll03"\nner_taskmodule = AutoTaskModule.from_pretrained(model_name_or_path)\nner_model = AutoModel.from_pretrained(model_name_or_path)\nner_pipeline = Pipeline(model=ner_model, taskmodule=ner_taskmodule, device=-1, num_workers=0)\n```\n\nOr, without `Auto` classes at all:\n\n```python\nfrom pytorch_ie.pipeline import Pipeline\nfrom pytorch_ie.models import TransformerSpanClassificationModel\nfrom pytorch_ie.taskmodules import TransformerSpanClassificationTaskModule\n\nmodel_name_or_path = "pie/example-ner-spanclf-conll03"\nner_taskmodule = TransformerSpanClassificationTaskModule.from_pretrained(model_name_or_path)\nner_model = TransformerSpanClassificationModel.from_pretrained(model_name_or_path)\nner_pipeline = Pipeline(model=ner_model, taskmodule=ner_taskmodule, device=-1, num_workers=0)\n```\n\n## âš¡ï¸ï¸ï¸ï¸ More Examples\n\n### Text-classification-based Relation Extraction\n\n```python\nfrom dataclasses import dataclass\n\nfrom pytorch_ie.annotations import BinaryRelation, LabeledSpan\nfrom pytorch_ie.auto import AutoPipeline\nfrom pytorch_ie.core import AnnotationList, annotation_field\nfrom pytorch_ie.documents import TextDocument\n\n\n@dataclass\nclass ExampleDocument(TextDocument):\n    entities: AnnotationList[LabeledSpan] = annotation_field(target="text")\n    relations: AnnotationList[BinaryRelation] = annotation_field(target="entities")\n\ndocument = ExampleDocument(\n    "â€œMaking a super tasty alt-chicken wing is only half of it,â€ said Po Bronson, general partner at SOSV and managing director of IndieBio."\n)\n\nre_pipeline = AutoPipeline.from_pretrained("pie/example-re-textclf-tacred", device=-1, num_workers=0)\n\nfor start, end, label in [(65, 75, "PER"), (96, 100, "ORG"), (126, 134, "ORG")]:\n    document.entities.append(LabeledSpan(start=start, end=end, label=label))\n\nre_pipeline(document, predict_field="relations", batch_size=2)\n\nfor relation in document.relations.predictions:\n    print(f"({relation.head} -> {relation.tail}) -> {relation.label}")\n\n# Result:\n# (Po Bronson -> SOSV) -> per:employee_of\n# (Po Bronson -> IndieBio) -> per:employee_of\n# (SOSV -> Po Bronson) -> org:top_members/employees\n# (IndieBio -> Po Bronson) -> org:top_members/employees\n```\n\n<!-- github-only -->\n\nâœ¨ðŸ“šâœ¨ [Read the full documentation](https://pytorch-ie.readthedocs.io/)\n\n## ðŸ”§ Development Setup\n\n## ðŸ… Acknowledgements\n\n-   This package is based on the [sourcery-ai/python-best-practices-cookiecutter](https://github.com/sourcery-ai/python-best-practices-cookiecutter) and [cjolowicz/cookiecutter-hypermodern-python](https://github.com/cjolowicz/cookiecutter-hypermodern-python) project templates.\n\n## ðŸ“ƒ Citation\n\nIf you find the framework useful please consider citing it:\n\n```bibtex\n@misc{alt2022pytorchie,\n    author={Christoph Alt, Arne Binder},\n    title = {PyTorch-IE: State-of-the-art Information Extraction in PyTorch},\n    year = {2022},\n    publisher = {GitHub},\n    journal = {GitHub repository},\n    howpublished = {\\url{https://github.com/ChristophAlt/pytorch-ie}}\n}\n```\n\n[license]: https://github.com/christophalt/pytorch-ie/blob/main/LICENSE\n',
    'author': 'Christoph Alt',
    'author_email': 'christoph.alt@posteo.de',
    'maintainer': None,
    'maintainer_email': None,
    'url': 'https://github.com/christophalt/pytorch-ie',
    'package_dir': package_dir,
    'packages': packages,
    'package_data': package_data,
    'install_requires': install_requires,
    'python_requires': '>=3.9,<4.0',
}


setup(**setup_kwargs)

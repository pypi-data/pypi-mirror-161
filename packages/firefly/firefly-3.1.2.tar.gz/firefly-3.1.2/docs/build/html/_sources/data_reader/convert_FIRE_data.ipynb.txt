{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/Users/ageller/VISUALIZATIONS/Firefly')\n",
    "sys.path.insert(0,'/Users/agurvich/research/repos/firefly/src')\n",
    "from firefly.data_reader import FIREreader,SimpleFIREreader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert FIRE data\n",
    "In this example notebook we demonstrate how to use the `firefly.data_reader.FIREreader` sub-class which creates specialized data files for FIRE formatted data. The details of how the `FIREreader` class is \"specialized\" see the <a href=\"https://ageller.github.io/Firefly/docs/build/html/reference/api/api.html\">API documentation</a> and to see the example of this output visit <a href=\"https://ageller.github.io/firefly/src/firefly/index.html\">the live demo version</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ptype 4\n",
      "/Users/agurvich/research/snaps/isolated_disks/Control_G4_20/snapdir_050/snapshot_050.hdf5\n",
      "Loading ptype 0\n",
      "/Users/agurvich/research/snaps/isolated_disks/Control_G4_20/snapdir_050/snapshot_050.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create a FIRE reader object\n",
    "reader = FIREreader(\n",
    "    ## path to directory containing (optionally multiple) .hdf5 files\n",
    "    snapdir = \"/Users/agurvich/research/snaps/isolated_disks/Control_G4_20/snapdir_050/\",\n",
    "    ## the snapshot number, best to provide separately in order to disambiguate\n",
    "    snapnum = 50,\n",
    "    ## particle types one would like to extract from .hdf5 files\n",
    "    ptypes=[0,4],\n",
    "    ## what to call them in the UI\n",
    "    UInames=['Gas','Stars'],\n",
    "    ## by what factor would we like to reduce the data for performance stability and disk space concerns\n",
    "    decimation_factors=[10,100],\n",
    "    ## what fields would we like to extract\n",
    "    fields=['Density','Velocities','Temperature'],\n",
    "    ## do we want to take the magnitude of any of these fields?\n",
    "    magFlags=[False,False,False],\n",
    "    ## do we want to take the log? \n",
    "    logFlags=[True,False,True],\n",
    "    ## which fields do we want to be able to filter on?\n",
    "    filterFlags=[True,True,True],\n",
    "    ## which fields do we want to be able to colormap by?\n",
    "    colormapFlags=[True,True,True],\n",
    "    ## where should the output .json files be saved to? \n",
    "    ##  if a relative path is given, like here, saves to $HOME/<JSONdir>\n",
    "    ##  and creates a soft-link to firefly/static/data\n",
    "    JSONdir=os.path.abspath(os.path.join(os.getcwd(),'..','static','data','FIREData_50')),\n",
    "    ## overwrite the existing startup.json file\n",
    "    write_startup=True)\n",
    "\n",
    "## fetch data from .hdf5 files\n",
    "reader.loadData()\n",
    "\n",
    "## set the color and size of the gas and star particles\n",
    "##  to be aesthetically pleasing\n",
    "reader.settings['color']['Gas']=[1,0,0,1]\n",
    "reader.settings['color']['Stars']=[0,0,1,1]\n",
    "reader.settings['sizeMult']['Gas']=1\n",
    "reader.settings['sizeMult']['Stars']=0.5\n",
    "reader.settings['camera'] = [0,0,-15]\n",
    "\n",
    "## dump output to .json files\n",
    "reader.dumpToJSON()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `firefly.data_reader.SimpleFIREreader`\n",
    "To simplify this process we have provided `firefly.data_reader.SimpleFIREreader` which takes a path to a FIRE snapshot and creates a \"standard\" iteration of Firefly given only a path to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ptype 4\n",
      "/Users/agurvich/research/snaps/isolated_disks/Control_G4_20/snapdir_050/snapshot_050.hdf5\n",
      "Loading ptype 0\n",
      "/Users/agurvich/research/snaps/isolated_disks/Control_G4_20/snapdir_050/snapshot_050.hdf5\n",
      "Outputting: Gas - 106666/1066668 particles - 3 tracked fields\n",
      "Outputting: Stars - 51411/514118 particles - 3 tracked fields\n"
     ]
    }
   ],
   "source": [
    "reader = SimpleFIREreader(\n",
    "    ## path to directory containing (optionally multiple) .hdf5 files\n",
    "    \"/Users/agurvich/research/snaps/isolated_disks/Control_G4_20/snapdir_050/\",\n",
    "    ## overwrite the existing startup.json file\n",
    "    write_startup=True, \n",
    "    ## pass absolute path to avoid symlink\n",
    "    JSONdir=os.path.abspath(os.path.join(os.getcwd(),'..','static','data','FIREData_50')))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

"""
Contains the functions that will download the market stack data.
"""
import asyncio
import json
from typing import List, Tuple
from itertools import chain

import aiohttp
from aiohttp import ClientSession
from pymarketstack.responses import Response, Pagination, Data
from pymarketstack.query import Query
from pymarketstack.helper import chunk
from pymarketstack.exceptions import *


async def _download_batch(url: str, session: ClientSession) -> Response | None:
    """
    Downloads a single batch [1, 1000] symbols, depending on the pagination limit set.

    :param url: The already constructed request url
    :param session: The client session provided by aiohttp
    :return: A Response object on success (or partial success), None on error, raises on fatal error.
    """

    async with session.get(url) as response:
        res = await response.content.read()
        content = res.decode()

        match ApiCodes(response.status):
            # Ok
            case ApiCodes.OK:
                return Response.from_json(content)

            # Non-fatal error
            case ApiCodes.BATCH:
                return None

            # Fatal errors:
            case ApiCodes.TOKEN:
                raise TokenException(Error.from_dict(json.loads(content)["error"]))

            case ApiCodes.ACCESS:
                raise AccessException(Error.from_dict(json.loads(content)["error"]))

            case ApiCodes.ENDPOINT:
                raise EndpointException(Error.from_dict(json.loads(content)["error"]))

            case ApiCodes.LIMIT:
                raise LimitException(Error.from_dict(json.loads(content)["error"]))

            case ApiCodes.INTERNAL:
                raise InternalException(Error.from_dict(json.loads(content)["error"]))

            case _:
                raise UnspecifiedException("An unknown error occurred downloading data.")


async def _spawner(query: Query, symbols: List[str]):
    # The amount of symbols per batch, each symbol downloads 'query.count' data, a batch can download at most-
    # 1000 pieces of data
    per_batch = 1000 // query.count

    # Split into batches, optimized to as few batches as possible
    batches = list(chunk(symbols, per_batch))
    batch_count = len(batches)

    connector = aiohttp.TCPConnector(limit=batch_count)
    async with aiohttp.ClientSession(connector=connector) as session:
        tasks = []
        for batch in batches:
            url = f"{query.url}&symbols={','.join(batch)}&limit={len(batch) * query.count}"
            tasks.append(asyncio.ensure_future(_download_batch(url, session)))

        return await asyncio.gather(*tasks, return_exceptions=False)


def quota(query: Query, *symbols: str) -> int:
    """
    Calculates how much quota will be used by a download. One quota equals to one batch/pagination.

    :param query: The query that will be used in a download.
    :param symbols: The symbols you want to download.
    :return: The amount of quota that will be used.
    """

    per_batch = 1000 // query.count
    batches = list(chunk(list(symbols), per_batch))
    return len(batches)


def download(query: Query, *symbols: str) -> Tuple[Response, List[str]]:
    """
    Spawns asyncio workers to download the tickers.

    :param query: The request query generated by one of the features.
    :param symbols: The symbols to download
    :return: A tuple containing the response and a list of possibly failed symbols.
    """

    # Await for all responses
    res = asyncio.run(_spawner(query, list(symbols)))
    responses = [response for response in res if response is not None]

    if len(responses) == 0:
        raise NoDataException(f"No valid data downloaded, a total of {res.count(None)} batches failed.")

    # Merge data
    data: List[Data] = list(chain(*[response.data for response in responses]))

    # Merge all paginations into one
    pagination = Pagination(
        limit=responses[0].pagination.limit,
        offset=responses[0].pagination.offset,
        count=responses[0].pagination.count,
        total=len(data)
    )

    # Succeeded symbols
    succeeded = [d.symbol for d in data]
    failed = [symbol for symbol in symbols if symbol not in succeeded]

    return Response(pagination, data), failed
